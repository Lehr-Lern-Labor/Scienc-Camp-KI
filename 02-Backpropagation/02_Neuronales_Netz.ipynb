{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronale Netze\n",
    "\n",
    "Neuronale Netze bestehen aus <b>Schichten</b> (engl. <b>layer</b>) von Neuronen. Ein Neuron ist nicht mit einem Neuron der gleichen Schicht verbunden, sondern mit bestimmten Neuronen der Vorgänger- und Nachfolgerschicht (falls vorhanden). Die erste Schicht bezeichnet man als <b>Eingabeschicht</b> (engl. <b>input layer</b>). Die Eingabeschicht muss genauso viele „Eingänge” haben, wie die Größe der Daten, die das neuronale Netz klassifizieren soll (z.B. muss ein neuronales Netz 784 Eingänge haben, wenn es 28 mal 28 Pixel große Schwarzweißbilder zu klassifizieren hat). Die letzte Schicht bezeichnet man als <b>Ausgabeschicht</b> (engl. <b>output layer</b>). Die Anzahl der Neuronen in der Ausgabeschicht muss mit der Anzahl der zu klassifiziereden Klassen übereinstimmen. Die Ausgabe eines Neuron $i$ in der Ausgabeschicht entspricht typischerweise einer Prozentangabe, die die Wahrscheinlichkeit angibt, dass der eingegebene Datenpunkt der Klasse $i$ angehört. Die Schichten zwischen der Ein- und Ausgabeschicht bezeichnet man als <b>versteckte Schichten</b> (engl. <b>hidden layers</b>). Wenn ein neuronales Netz viele versteckte Schichten hat, bezeichnet man als es <b>tiefes neuronales Netz</b> (engl. <b>deep neural network</b>).\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    " <figure>\n",
    "  <img src=\"img/deep_neural_network.webp\" alt=\"Deep Neural Network\" style=\"width:45%\">\n",
    "  <figcaption></figcaption>\n",
    "</figure> \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "In der gezeigten Darstellung findet die Verarbeitung der „Signale“ in den Kreisen statt. Hier werden die gewichteten Eingaben zu einer Summe addiert, um anschließend die Summe in eine Aktivierungsfunktion einzusetzen. Du kennst bereits vom Perzeptron die Treppenfunktion als Aktivierungsfunktion. In neuronalen Netzen werden andere Aktivierungsfunktionen benutzt. Drei wichtige Aktivierungsfunktionen sind die Sigmoid-Funktion, die Tangens-hyberbolicus-Funktion und der insbesondere die <b>ReLu-Funktion</b>. \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    " <figure>\n",
    "  <img src=\"img/activation.webp\" alt=\"Aktivierungsfunktionen\" style=\"width:65%\">\n",
    "  <figcaption></figcaption>\n",
    "</figure> \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "<i class=\"fa fa-laptop\" style=\"font-size:38px\"></i>\n",
    "\n",
    "<i>Setze die ReLu-Funktion in Code um.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Füge hier deinen Code ein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An den Verbindungen zwischen den Schichten werden die Gewichte geschrieben, mit denen die jeweilige Ausgabe eines Neurons multipliziert wird, um anschließend als Eingabe für das andere Neuron zu dienen. Wenn wir davon sprechen, dass wir ein neuronale Netz trainieren, dann machen wir nichts anderes, als die Gewichte an unsere Daten anzupassen. Nur diese Gewichte ändern sich die im Laufe des Trainings; alles andere bleibt gleich.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    " <figure>\n",
    "  <img src=\"img/weights.webp\" alt=\"weights\" style=\"width:30%\">\n",
    "  <figcaption></figcaption>\n",
    "</figure> \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Diese Gewichte müssen irgendwie gespeichert werden. Dafür verwendet man Tensoren, die im nächsten Abschnitt vorgestellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Führe dieses Codefeld aus, um die notwendigen Bibliotheken zu importieren.\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensoren\n",
    "\n",
    "Möchtest du gleich mehrere Zahlen in einem Objekt speichern, kannst du dafür Matrizen / Arrays verwenden. Wir möchten die Gewichte zwischen jeder Schicht als Matrizen speichern.\n",
    "\n",
    "\n",
    " <figure>\n",
    "  <img src=\"img/matrix.png\" alt=\"matrix\" style=\"width:35%\">\n",
    "  <figcaption></figcaption>\n",
    "</figure> \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Du kennst bereits die Arrays aus der Bibliothek <i>numpy</i>. Die Arrays von <i>torch</i> unterscheiden sich nur im Detail von den bereits bekannten Arrays und werden <b>Tensoren</b> genannt. Mache dich im folgenden Codefeld mit diesen vertraut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form des Tensors:  torch.Size([4, 5])\n",
      "tensor([[0.7748, 0.1872, 0.6274, 0.0749, 0.3580]])\n",
      "tensor([0.7748, 0.1872, 0.6274, 0.0749, 0.3580])\n",
      "Eintrag=  tensor([1., 1., 1., 1., 1.])\n",
      "Zahl=  0.46636438369750977\n"
     ]
    }
   ],
   "source": [
    "# Erzeugt einen Tensor mit zufälligen 1 x 4 Einträgen.\n",
    "t1 = torch.rand(4)\n",
    "# Erzeugt einen Tensor mit zufälligen 2 x 3 Einträgen.\n",
    "t2 = torch.rand(2, 3)\n",
    "\n",
    "# Erzeugt einen Tensor mit 1 x 10 0-Einträgen.\n",
    "t3 = torch.zeros(10)\n",
    "# Erzeugt einen Tensor mit 4 x 5 1-Einträgen.\n",
    "t4 = torch.ones(4,5)\n",
    "\n",
    "# Mit folgendem Befehl kannst du dir die Größe / „Form“ des Tensors ausgeben lassen.\n",
    "print(\"Form des Tensors: \", t4.shape)\n",
    "\n",
    "# Möchtest du eine Eintrag aus dem Tensor ausgeben lassen, kannst du den Tensor indizieren.\n",
    "eintrag = t4[0]\n",
    "\n",
    "# Mit [:a] und [a:] kannst du dir nur einen Teil des Tensors ausgeben lassen.\n",
    "t2[:2]\n",
    "t2[2:]\n",
    "\n",
    "# Mit folgendem Befehl kannst du eine Zahl aus einem Tensor ausgeben lassen.\n",
    "zahl = t2[0][0].item()\n",
    "\n",
    "# Mit folgendem Befehl kannst du den Tensor in eine andere Form umformen.\n",
    "t5 = t4\n",
    "t5.reshape(20,)\n",
    "\n",
    "# Mit folgendem Befehl kannst du zwei Tensoren miteinander verbinden.\n",
    "torch.cat((torch.rand(2,2), torch.rand(2,2)), 0)\n",
    "\n",
    "# Mit folgendem Befehl kannst du alle Einträgt aufsummieren.\n",
    "sum(t5)\n",
    "\n",
    "# ein weiterer nützlicher Befehl:\n",
    "t6 = torch.rand(1,5)\n",
    "print(t6)\n",
    "t6 = t6.squeeze(0)\n",
    "print(t6)\n",
    "\n",
    "print(\"Eintrag= \", eintrag)\n",
    "print(\"Zahl= \", zahl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "\n",
    "<img style=\"float: left;\" src=\"img/laptop_icon.png\" width=50 height=50 /> <br><br>\n",
    "\n",
    "<i>Vervollständige das Codefeld, indem du den Anweisungen folgst.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[2, 3, 7], [1, 8, 10]])\n",
    "\n",
    "# Gebe die Form des Tensors t aus.\n",
    "\n",
    "\n",
    "# Gebe den ersten Eintrag der ersten Zeile aus.\n",
    "\n",
    "\n",
    "# Gebe den zweiten Eintrag der zweiten Zeile als Integer-Zahl aus.\n",
    "\n",
    "\n",
    "# Erzeuge einen Tensor, der Form 1 x 5 und nur aus 2en als Einträge hat.\n",
    "\n",
    "\n",
    "# Erzeuge zwei zufällige Tensoren der Form 2 x 2 und multipliziere die entsprechenden Einträge miteinander. \n",
    "\n",
    "\n",
    "# Verbinde deine zwei erzeugten Tensoren zu einem Tensor.\n",
    "\n",
    "\n",
    "# Forme den neuen Tensor in die Form mit 1 x 8 Einträgen um und addiere zu jedem Wert 2 dazu.\n",
    "\n",
    "\n",
    "# Lösche die letzen beiden Einträge des letzen Tensors. \n",
    "\n",
    "\n",
    "# Forme den Tensor t in die Form mit 1 x 6 Einträgen um\n",
    "\n",
    "\n",
    "# Berechne die Differenz der jeweiligen Einträge des aktuellen Tensors und t und summiere sie auf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten erzeugen\n",
    "\n",
    "Um neuronale Netze trainieren zu können, benötigen wir <b>gelabelte</b> Daten. Die gelabelten Daten mit denen die Gewichte angepasst werden, werden <b>Trainigsdaten</b> genannt. Um die Performance des neuronalen Netzes zu beurteilen, benötigen wir gelabelte Daten, auf denen das neuronale Netz <i>nicht</i> trainiert. Diese Daten werden <b>Testdaten</b> genannt. \n",
    "____\n",
    "\n",
    "\n",
    "<img style=\"float: left;\" src=\"img/laptop_icon.png\" width=50 height=50 /> <br><br>\n",
    "\n",
    "<i>Erzeuge 100 gelabelte Datenpunkte für den Trainingsdatensatz und 20 für den Testdatensatz im Intervall $0$ bis $1$. Die Punkte gehören entweder der Klasse $0$ oder $1$ an. Die beiden Klassen sollen dabei nicht durch eine Gerade getrennt werden können. Du kannst z.B. die Funktion $f(x)=x^2$ als Trennline der beiden Klassen verwenden</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Füge hier deinen Code ein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "\n",
    "<img style=\"float: left;\" src=\"img/laptop_icon.png\" width=50 height=50 /> <br><br>\n",
    "\n",
    "<i>Erzeuge nun einen Trainigs- und Testdatensatz für 4 Klassen.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Füge hier deinen Code ein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronale Netze\n",
    "\n",
    "In diesem Abschnitt lernst du, wie du mithilfe der Bibliothek <i>PyTorch</i> neuronale Netze sehr einfach erstellen und trainieren kannst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1841e-01, 5.8950e-03, 8.7490e-01, 7.9781e-04])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/anaconda3/envs/acl/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0186, -0.0168,  0.1946],\n",
       "        [-0.0537,  0.5568,  0.0379],\n",
       "        [ 0.3440,  0.5178,  0.5273]], requires_grad=True)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erzeugt eine Schicht mit drei Inputs und drei Outputs.\n",
    "layer = torch.nn.Linear(3,3)\n",
    "gewichte_layer1 = layer.weight\n",
    "bias_layer1 = layer.bias\n",
    "\n",
    "# Aktivierungsfunktion ReLU und Softmax\n",
    "softmax = torch.nn.Softmax()\n",
    "relu = torch.nn.ReLU()\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "input = torch.tensor([1.0, -2.0, 3.0, -4.0])\n",
    "output = relu(input)\n",
    "output = sigmoid(input)\n",
    "\n",
    "torch.tensor([0.4, 0.15, 3.8, 2.3])\n",
    "output = softmax(input)\n",
    "print(output)\n",
    "\n",
    "layer1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_in, num_out):\n",
    "        super(Net, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    # Neuronales Netz mit ReLU-Funktion\n",
    "    \n",
    "    def forward(self, x):    \n",
    "        pass\n",
    "    \n",
    "    def train_model(self, train_data, train_labels, lr):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = self(train_data)\n",
    "        loss = loss_fn(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    def test(self, test_data, test_labels):\n",
    "        self.train(False)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        outputs = self(test_data)\n",
    "        loss = loss_fn(outputs, test_labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "\n",
    "<img style=\"float: left;\" src=\"img/laptop_icon.png\" width=50 height=50 /> <br><br>\n",
    "\n",
    "<i>Implementiere eine Funktion, die die Genauigkeit des neuronalen Netzes auf den gegebenen Daten auswertet.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Füge hier deinen Code ein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "\n",
    "<img style=\"float: left;\" src=\"img/laptop_icon.png\" width=50 height=50 /> <br><br>\n",
    "\n",
    "<i>Implementiere eine Methode für den ganzen Trainingsablauf. Als Parameter werden der Traingsdatensatz mit den Labels, der Testdatensatz mit den Labels, die Lernrate und die Anzahl der Epochen übergeben.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Füge hier deinen Code ein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "\n",
    "<img style=\"float: left;\" src=\"img/laptop_icon.png\" width=50 height=50 /> <br><br>\n",
    "\n",
    "<i>Berechne nach jeder Epoche den gesamten Fehler und die Genauigkeit auf den Daten und zeichne die Punkte in einem Koordinatensystem mithilfe von PyPlot ein.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting und Overfitting\n",
    "\n",
    "Trainierst du dein neuronales Netz zu wenig, so wird es deine Daten nicht gut klassifizieren können. Dieses Phänomen bezeichnet man als <b>Underfitting</b>. Trainierst du dein neuronales Netz zu lange, so lernt es die Trainingsdaten auswendig und die Performance auf unbekannten Daten, also auf den Testdaten, sinkt. Das bezeichnet man als <b>Overfitting</b>. Du musst also eine gute Balance zwischen zu wenig und zu viel Training finden. Dafür kannst du dich dafür am Loss auf den Testdaten orientieren.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    " <figure>\n",
    "  <img src=\"img/overfitting.png\" alt=\"Overfitting\" style=\"width:40%\">\n",
    "  <figcaption></figcaption>\n",
    "</figure> \n",
    "\n",
    "&nbsp;\n",
    "____\n",
    "\n",
    "\n",
    "<img style=\"float: left;\" src=\"img/laptop_icon.png\" width=50 height=50 /> <br><br>\n",
    "\n",
    "<i>Um Overfitting zu vermeiden, kannst du das aktuell beste Model immer speichern. Speichere also oben in deinem Trainingsablauf immer das beste Modell ab.</i>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
